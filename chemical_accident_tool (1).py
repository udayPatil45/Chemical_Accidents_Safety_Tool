# -*- coding: utf-8 -*-
"""Chemical_Accident_tool.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kXD-Etg2x-lUJkAp_3bWLE8savHuqrjd
"""

!pip install pdfplumber

!pip install faiss-cpu

!pip install streamlit

import os
import re
import pdfplumber
import pandas as pd
import numpy as np
import faiss
import streamlit as st
import requests
from sentence_transformers import SentenceTransformer

import os
import re
import pdfplumber
import pandas as pd
import numpy as np
from google.colab import files
from io import BytesIO
from zipfile import ZipFile

# --- Upload PDF files ---
uploaded = files.upload()

# --- Extract case details from PDF text ---
def extract_case_details(text):
    text = text.replace('\n', ' ').replace('  ', ' ')
    title = re.search(r'Title:\s*(.*?)\.', text)
    location = re.search(r'Location:\s*(.*?)\.', text)
    date = re.search(r'Dt\.:\s*(\d{2}/\d{2}/\d{4})', text)
    return {
        'title': title.group(1) if title else '',
        'location': location.group(1) if location else '',
        'date': date.group(1) if date else '',
        'text': text
    }

# --- Read PDFs and extract data ---
data_rows = []

for filename in uploaded.keys():
    with pdfplumber.open(BytesIO(uploaded[filename])) as pdf:
        full_text = ""
        for page in pdf.pages:
            full_text += page.extract_text() or ""
        if full_text.strip():
            data_rows.append(extract_case_details(full_text))

# --- Create DataFrame and export to CSV ---
df = pd.DataFrame(data_rows, columns=['title', 'location', 'date', 'text'])

if df.empty:
    raise ValueError("No valid PDF text extracted. Check uploaded files.")

csv_path = "extracted_case_data.csv"
df.to_csv(csv_path, index=False)

print(f"‚úÖ Extraction complete. {len(df)} cases saved to {csv_path}")

# --- Download the CSV ---
files.download(csv_path)

# --- Create DataFrame and CSV ---
df = pd.DataFrame(data_rows, columns=['title', 'location', 'date', 'text'])
if df.empty:
    raise ValueError("No valid PDF text extracted. Check your files.")
df.to_csv(csv_path, index=False)

# --- Embedding text ---
df = pd.read_csv(csv_path).fillna("N/A")
texts = df['text'].tolist()

embedder = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True).astype("float32")

# --- FAISS index ---
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

import requests
import json

def generate_answer(question, context):
    prompt = f"""Use the following context to answer the question:

Context:
{context}

Question:
{question}

Answer:"""

    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "tinyllama",
            "prompt": prompt,
            "stream": True
        },
        stream=True
    )

    output = ""
    for line in response.iter_lines():
        if line:
            data = json.loads(line.decode('utf-8'))
            output += data.get("response", "")

    return output

# --- Streamlit app ---
st.title("üìÑ Accident Case Chatbot")
query = st.text_input("üîç Ask a question:")

if query:
    q_emb = embedder.encode([query], convert_to_numpy=True).astype("float32")
    _, I = index.search(q_emb, k=3)

    context = "\n\n".join(texts[i] for i in I[0])
    answer = generate_answer(query, context)

    st.markdown("### ‚úÖ Answer:")
    st.write(answer)

    st.markdown("### üìö Context Used:")
    for i in I[0]:
        st.write(f"- {texts[i][:300]}...")